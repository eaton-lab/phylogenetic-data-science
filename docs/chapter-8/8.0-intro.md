---
---

## In progress.


### Likelihood
In statistics, the likelihood is defined as **the probability of observing 
data given a parameterized model**. In practice, we have usually have data 
in the form of an observation, and want to know the parameters of a model, 
as a way of interpreting the observation in a statistical way. 

**Maximum likelihood estimation** is a method for estimating the parameters 
of a model based on observed data. It aims to find the model parameters that 
best fit the data. Once you understand the basic outline of the Maximum 
likelihood approach, it can be intuitive, and even simple to implement. For 
this reason it has become widely used. However, there are several common
mistakes or misconceptions that are often made when first learning 
likelihood that we will aim to dispel here. 


### Probability and Likelihood
What is the difference between a probability and a likelihood? 
- probability distribution sums to 1.
- likelihood distribution is not required to sum to 1, and can be infinite?
- https://jaketae.github.io/study/likelihood/


### Statistical Models
In order to test and compare hypotheses about the way the world works
we often formulate our hypotheses into statistical models -- simplified 
mathematical representations. In order to simplify the world of possible 
outcomes, such models are usually formulated to describe a 
*generative process*, based on statistical assumptions, for how a 
set of observed data could be generated. 

For example, if were modeling a coin toss we could assume the heads and 
tails are the only possible outcomes, and each toss is statistically 
independent of the results of any previous toss. Similarly, if we were 
modeling a linear relationship between height and weight we would assume
that these two variables have a linear relationship and that any deviations
from this line will be randomly distributed according to a normal 
distribution. These assumptions are imperfect -- it is possible, though
unlikely, that a coin toss could land on its thin edge, and similarly, 
that that the relationship between height and weight is strongly 
dependent on other variables, or that the error is distributed 
non-normally. 

### Phylogenetic likelihoods
The goal of maximum likelihood in phylogenetics is to find the best set of 
model parameters to explain a set of observed data. This is the same 
description as above, for very different types of models, and that is fine,
since phylogenetic models themselves can also come in many different forms, 
as can the data. For example, the data that is being fit in a phylogenetic 
model may be many different types of discrete or continuous character data, 
from morphology to genetic sequences, to biogeograpic observations. Many 
of the most exciting new phylogenetic inference methods aim to combine
many of these types of data into a single integrated analyses, as can be
performed in the software RevBayes [cite]. 

### An introduction to likelihood



### Generative Models
An incredibly useful procedure to ... `numpy.random` package. 

```py
# initialize a random number generator from a seed
rng = np.random.default_rng(seed=123)

# sample from a binomial statistical distribution with p=0.5
tosses = rng.binomical(n=1, p=0.5, size=1000)

# sample from a normal distribution with std=0.5
errors = rng.normal(scale=0.5, size=1000)
```


### Bayesian statistics

$$
P(H|D) = \frac{P(H~and~D)}{P(D)} = P(D|H)\frac{P(H)}{P(D)}
$$

Therefore,

$$
\frac{P(H_1|D) = P(D|H_1)~P(D)} {P(H_2|D) = P(D|H_2)~P(D)}
$$

